# Robots.txt for Spacire Blog Data Repository
# This file prevents search engines from crawling and indexing the data files

User-agent: *
Disallow: /
Crawl-delay: 86400

# Block all bots from accessing any content
User-agent: Googlebot
Disallow: /

User-agent: Bingbot
Disallow: /

User-agent: Slurp
Disallow: /

User-agent: DuckDuckBot
Disallow: /

User-agent: Baiduspider
Disallow: /

User-agent: YandexBot
Disallow: /

# Block archiving bots
User-agent: ia_archiver
Disallow: /

User-agent: Wayback Machine
Disallow: /

# Block SEO and analysis bots
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: DotBot
Disallow: /

# No sitemap provided
Sitemap:
